{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97299606",
   "metadata": {},
   "source": [
    "# Model Training and Selection\n",
    "\n",
    "This notebook loads the processed features, splits the data, and trains two models (Logistic Regression and Random Forest) with hyperparameter tuning using Grid Search. Results and best parameters are reported for each model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "073c8e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.train import (split_data, grid_search_logistic_regression, \n",
    "                       grid_search_random_forest, evaluate_model_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e278b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data\n",
    "df = pd.read_csv('../data/processed/features_with_risk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a3ff48e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (76529, 36), Test shape: (19133, 36)\n",
      "Train target distribution:\n",
      "is_high_risk\n",
      "0    0.884802\n",
      "1    0.115198\n",
      "Name: proportion, dtype: float64\n",
      "Test target distribution:\n",
      "is_high_risk\n",
      "0    0.884806\n",
      "1    0.115194\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split the data\n",
    "target_col = 'is_high_risk'\n",
    "X_train, X_test, y_train, y_test = split_data(df, target_col=target_col)\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}, Test shape: {X_test.shape}\")\n",
    "print(f\"Train target distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"Test target distribution:\\n{y_test.value_counts(normalize=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25e26c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'C': 0.01, 'max_iter': 1000, 'solver': 'liblinear'}\n",
      "Tuned Logistic Regression Results:\n",
      "Accuracy: 0.8848\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC-AUC: 0.7740343758747299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94     16929\n",
      "           1       0.00      0.00      0.00      2204\n",
      "\n",
      "    accuracy                           0.88     19133\n",
      "   macro avg       0.44      0.50      0.47     19133\n",
      "weighted avg       0.78      0.88      0.83     19133\n",
      "\n",
      "Accuracy: 0.8848\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "ROC-AUC: 0.7740343758747299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.94     16929\n",
      "           1       0.00      0.00      0.00      2204\n",
      "\n",
      "    accuracy                           0.88     19133\n",
      "   macro avg       0.44      0.50      0.47     19133\n",
      "weighted avg       0.78      0.88      0.83     19133\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\KAIM\\week5\\credit-risk-probability-model-week5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "e:\\KAIM\\week5\\credit-risk-probability-model-week5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "e:\\KAIM\\week5\\credit-risk-probability-model-week5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "e:\\KAIM\\week5\\credit-risk-probability-model-week5\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8848063555114201,\n",
       " 'precision': 0.0,\n",
       " 'recall': 0.0,\n",
       " 'f1': 0.0,\n",
       " 'roc_auc': 0.7740343758747299}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning for Logistic Regression\n",
    "tuned_logreg = grid_search_logistic_regression(X_train, y_train)\n",
    "print('Tuned Logistic Regression Results:')\n",
    "evaluate_model_full(tuned_logreg, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb83ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'max_depth': None, 'n_estimators': 100}\n",
      "Tuned Random Forest Results:\n",
      "Accuracy: 0.9966\n",
      "Precision: 0.9842\n",
      "Recall: 0.9864\n",
      "F1 Score: 0.9853\n",
      "ROC-AUC: 0.9997970733754158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16929\n",
      "           1       0.98      0.99      0.99      2204\n",
      "\n",
      "    accuracy                           1.00     19133\n",
      "   macro avg       0.99      0.99      0.99     19133\n",
      "weighted avg       1.00      1.00      1.00     19133\n",
      "\n",
      "Accuracy: 0.9966\n",
      "Precision: 0.9842\n",
      "Recall: 0.9864\n",
      "F1 Score: 0.9853\n",
      "ROC-AUC: 0.9997970733754158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16929\n",
      "           1       0.98      0.99      0.99      2204\n",
      "\n",
      "    accuracy                           1.00     19133\n",
      "   macro avg       0.99      0.99      0.99     19133\n",
      "weighted avg       1.00      1.00      1.00     19133\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.9966027282705273,\n",
       " 'precision': 0.98415572657311,\n",
       " 'recall': 0.9863883847549909,\n",
       " 'f1': 0.98527079084523,\n",
       " 'roc_auc': 0.9997970733754158}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameter tuning for Random Forest\n",
    "tuned_rf = grid_search_random_forest(X_train, y_train)\n",
    "print('Tuned Random Forest Results:')\n",
    "evaluate_model_full(tuned_rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0aea98",
   "metadata": {},
   "source": [
    "The best model is Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4cbb6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/14 15:54:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/14 15:55:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2025/07/14 15:55:02 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'CreditRiskRandomForest' already exists. Creating a new version of this model...\n",
      "2025/07/14 15:55:02 WARNING mlflow.tracking._model_registry.fluent: Run with id 12f399cf76954b79bf13495014dc594a has no artifacts at artifact path 'random_forest_model', registering model based on models:/m-acae83003d13465ca44089330cc8f7e4 instead\n",
      "Registered model 'CreditRiskRandomForest' already exists. Creating a new version of this model...\n",
      "2025/07/14 15:55:02 WARNING mlflow.tracking._model_registry.fluent: Run with id 12f399cf76954b79bf13495014dc594a has no artifacts at artifact path 'random_forest_model', registering model based on models:/m-acae83003d13465ca44089330cc8f7e4 instead\n",
      "Created version '4' of model 'CreditRiskRandomForest'.\n",
      "Created version '4' of model 'CreditRiskRandomForest'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model registered in MLflow Model Registry: CreditRiskRandomForest (version 4)\n"
     ]
    }
   ],
   "source": [
    "# Register the best model (Random Forest) in MLflow Model Registry\n",
    "mlflow.set_experiment('Credit Risk Modeling')\n",
    "with mlflow.start_run(run_name='Best Random Forest Model'):\n",
    "    mlflow.sklearn.log_model(tuned_rf, 'random_forest_model')\n",
    "    mlflow.log_param('model_type', 'RandomForestClassifier')\n",
    "    mlflow.log_params(tuned_rf.get_params())\n",
    "    mlflow.log_metric('test_roc_auc', tuned_rf.score(X_test, y_test))\n",
    "    # Register the model\n",
    "    result = mlflow.register_model(\n",
    "        \"runs:/\" + mlflow.active_run().info.run_id + \"/random_forest_model\",\n",
    "        \"CreditRiskRandomForest\"\n",
    "    )\n",
    "    print(f\"Model registered in MLflow Model Registry: {result.name} (version {result.version})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
